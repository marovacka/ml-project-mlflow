{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d826d6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.recipes import Recipe\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a0bf889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6], 'target': ['a', 'b', 'c']})\n",
    "df.to_csv('../data/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35b7be5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/03 11:52:33 INFO mlflow.recipes.recipe: Creating MLflow Recipe 'my_project' with profile: 'local'\n"
     ]
    }
   ],
   "source": [
    "r = Recipe(profile=\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88375811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31991d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6951451a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "  <body>\n",
       "    <style>\n",
       "      @keyframes spin {\n",
       "        to { transform: translate(calc(-50%), calc(50vh - 50%)) rotate(360deg); }\n",
       "      }\n",
       "      .mermaidTooltip {\n",
       "        display: none;\n",
       "      }\n",
       "      .wrapper {\n",
       "        display: flex;\n",
       "      }\n",
       "      .mermaid {\n",
       "        width: 60%;\n",
       "      }\n",
       "      .pane-loading {\n",
       "        font-size: 0;\n",
       "        color: transparent;\n",
       "      }\n",
       "      .pane-loading::after {\n",
       "        content: \"\";\n",
       "        position: absolute;\n",
       "        inset: 0 50%;\n",
       "        width: 32px;\n",
       "        height: 32px;\n",
       "        transform: translate(calc(-50%), calc(50vh - 50%));\n",
       "        border: 0.25rem solid #9370DB;\n",
       "        border-bottom: 0.25rem solid rgba(0,0,0,0);\n",
       "        border-radius: 50%;\n",
       "        animation: spin 1s linear infinite;\n",
       "      }\n",
       "      #editor {\n",
       "        font-size: 13px;\n",
       "        width: 40%;\n",
       "        position: relative;\n",
       "      }\n",
       "      font {\n",
       "        font-size: 24px;\n",
       "        padding: 24px;\n",
       "      }\n",
       "      .node:hover {\n",
       "        stroke: #2272B4 !important;\n",
       "        color: #0E538B !important;\n",
       "        background-color: #bbdaf4;\n",
       "      }\n",
       "    </style>\n",
       "\n",
       "    <div class=\"wrapper\">\n",
       "      <div class=\"mermaid pane-loading\">\n",
       "          flowchart TD\n",
       "\n",
       "          subgraph \" \"\n",
       "            recipe([recipe.yaml])\n",
       "\n",
       "            ingestUserCode([steps/ingest.py]) --> ingestMLPStep[[\"<font>ingest</font>\"]]\n",
       "            ingestMLPStep --> dataParquet[(ingested_data)]\n",
       "\n",
       "            ingestScoringUserCode([steps/ingest.py]) --> ingestScoringMLPStep[[\"<font>ingest_scoring</font>\"]]\n",
       "            ingestScoringMLPStep --> dataScoringParquet[(ingested_scoring_data)]\n",
       "\n",
       "            dataScoring[(ingested_scoring_data)] --> predictMLPStep[[\"<font>predict</font>\"]]\n",
       "            predictMLPStep --> dataScored[(scored_data)]\n",
       "          end\n",
       "\n",
       "          data[(ingested_data)] --> splitStep[[\"<font>split</font>\"]]\n",
       "          transformUserCode([steps/transform.py]) --> transformMLPStep\n",
       "          splitUserCode([steps/split.py]) --> splitStep\n",
       "          splitStep --> splitData0[(training_data)]\n",
       "          splitStep --> splitData1[(validation_data)]\n",
       "          splitStep --> splitData2[(test_data)]\n",
       "          splitData0 --> transformMLPStep[[\"<font>transform</font>\"]]\n",
       "          splitData1 --> transformMLPStep[[\"<font>transform</font>\"]]\n",
       "\n",
       "          transformMLPStep --> transformedParquet[(transformed_training_data, <br/> transformed_validation_data)]\n",
       "          transformMLPStep --> transformer\n",
       "          transformedParquet --> trainMLPStep[[\"<font>train</font>\"]]\n",
       "\n",
       "          trainUserCode([steps/train.py]) --> trainMLPStep\n",
       "          customMetricsUserCode([steps/custom_metrics.py]) --> trainMLPStep\n",
       "          transformer --> trainMLPStep\n",
       "          trainMLPStep --> run\n",
       "          trainMLPStep --> model\n",
       "          trainMLPStep --> predictedTrainingData[(predicted_training_data)]\n",
       "\n",
       "          model --> evaluateMLPStep[[\"<font>evaluate</font>\"]]\n",
       "          splitData1 --> evaluateMLPStep\n",
       "          splitData2 --> evaluateMLPStep\n",
       "          customMetricsUserCode --> evaluateMLPStep\n",
       "          evaluateMLPStep --> model_validation_status\n",
       "          run --> registerMLPStep[[\"<font>register</font>\"]]\n",
       "          run --> evaluateMLPStep\n",
       "\n",
       "          model_validation_status --> registerMLPStep\n",
       "          registerMLPStep --> registered_model_version\n",
       "\n",
       "          click ingestMLPStep renderMoreInformation \"{'help_string': 'The &bsol;&#39;ingest&bsol;&#39; step resolves the dataset specified by the &bsol;&#39;steps.ingest&bsol;&#39; section in recipe.yaml and converts it to parquet format, leveraging the custom dataset parsing code defined in `steps/ingest.py` (and referred to by the &bsol;&#39;loader_method&bsol;&#39; attribute of the &bsol;&#39;steps.ingest&bsol;&#39; section in recipe.yaml) if necessary. Subsequent steps convert this dataset into training, validation, & test sets and use them to develop a model. An example recipe.yaml &bsol;&#39;steps.ingest&bsol;&#39; configuration is shown below.\\n\\nsteps.ingest:\\n  location: https://nyc-tlc.s3.amazonaws.com/trip+data/yellow_tripdata_2022-01.parquet\\n  using: {{INGEST_DATA_FORMAT|default(&bsol;&#39;parquet&bsol;&#39;)}}\\n  loader_method: load_file_as_dataframe\\n', 'help_string_type': 'text'}\"\n",
       "          click ingestUserCode renderMoreInformation \"{'help_string': '&bsol;#quot;&bsol;#quot;&bsol;#quot;\\nsteps/ingest.py defines customizable logic for parsing arbitrary dataset formats (i.e. formats that are not natively parsed by MLflow Recipes) via the `load_file_as_dataframe` function. Note that the Parquet, Delta, and Spark SQL dataset formats are natively parsed by MLflow Recipes, and you do not need to define custom logic for parsing them. An example `load_file_as_dataframe` implementation is displayed below (note that a different function name or module can be specified via the &bsol;&#39;loader_method&bsol;&#39; attribute of the &bsol;&#39;data&bsol;&#39; section in recipe.yaml).\\n&bsol;#quot;&bsol;#quot;&bsol;#quot;\\n\\ndef load_file_as_dataframe(\\n    file_path: str,\\n    file_format: str,\\n) -> pandas.DataFrame:\\n    &bsol;#quot;&bsol;#quot;&bsol;#quot;\\n    Load content from the specified dataset file as a Pandas DataFrame.\\n\\n    This method is used to load dataset types that are not natively  managed by MLflow Recipes (datasets that are not in Parquet, Delta Table, or Spark SQL Table format). This method is called once for each file in the dataset, and MLflow Recipes automatically combines the resulting DataFrames together.\\n\\n    :param file_path: The path to the dataset file.\\n    :param file_format: The file format string, such as &bsol;#quot;csv&bsol;#quot;.\\n    :return: A Pandas DataFrame representing the content of the specified file.\\n    &bsol;#quot;&bsol;#quot;&bsol;#quot;\\n', 'help_string_type': 'python'}\"\n",
       "          click splitStep renderMoreInformation \"{'help_string': 'The &bsol;&#39;split&bsol;&#39; step splits the ingested dataset produced by the &bsol;&#39;ingest&bsol;&#39; step into a training dataset for model training, a validation dataset for model performance evaluation & tuning, and a test dataset for model performance evaluation. The fraction of records allocated to each dataset is defined by the &bsol;&#39;split_ratios&bsol;&#39; attribute of the &bsol;&#39;split&bsol;&#39; step definition in recipe.yaml. The split step also preprocesses the datasets using logic defined in `steps/split.py` (and referred to by the &bsol;&#39;post_split_method&bsol;&#39; attribute of the &bsol;&#39;split&bsol;&#39; step definition in recipe.yaml). Subsequent steps use these datasets to develop a model and measure its performance. An example recipe.yaml &bsol;&#39;split&bsol;&#39; step definition is shown below.\\n\\nsteps:\\n  split:\\n    split_ratios: {{SPLIT_RATIOS|default([0.75, 0.125, 0.125])}}\\n    post_split_filter_method: create_dataset_filter\\n', 'help_string_type': 'text'}\"\n",
       "          click transformMLPStep renderMoreInformation \"{'help_string': 'The &bsol;&#39;transform&bsol;&#39; step uses the training dataset produced by &bsol;&#39;split&bsol;&#39; to fit a transformer with the transformation operations defined in `steps/transform.py` (and referred to by the &bsol;&#39;transformer_method&bsol;&#39; attribute of the &bsol;&#39;transform&bsol;&#39; step definition in recipe.yaml). The transformer is then applied to the training dataset and the validation dataset, producing transformed datasets that are used by subsequent steps for estimator training and model performance evaluation. An example recipe.yaml &bsol;&#39;transform&bsol;&#39; step definition is shown below.\\n\\nsteps:\\n  transform:\\n    using: custom\\n    transformer_method: transformer_fn\\n', 'help_string_type': 'text'}\"\n",
       "          click transformUserCode renderMoreInformation \"{'help_string': '&bsol;#quot;&bsol;#quot;&bsol;#quot;\\nsteps/transform.py defines customizable logic for transforming input data during model inference. Transformations are specified via the via the `transformer_fn` function, an example of which is displayed below (note that a different function name or module can be specified via the &bsol;&#39;transformer_method&bsol;&#39; attribute of the &bsol;&#39;transform&bsol;&#39; step definition in recipe.yaml).\\n&bsol;#quot;&bsol;#quot;&bsol;#quot;\\n\\ndef transformer_fn():\\n    &bsol;#quot;&bsol;#quot;&bsol;#quot;\\n    Returns an *unfitted* transformer that defines ``fit()`` and ``transform()`` methods. The transformer&bsol;&#39;s input and output signatures should be compatible with scikit-learn transformers.\\n    &bsol;#quot;&bsol;#quot;&bsol;#quot;\\n', 'help_string_type': 'python'}\"\n",
       "          click trainMLPStep renderMoreInformation \"{'help_string': 'The &bsol;&#39;train&bsol;&#39; step uses the transformed training dataset produced by &bsol;&#39;transform&bsol;&#39; to fit an estimator with the type and parameters defined in `steps/train.py` (and referred to by the &bsol;&#39;estimator_method&bsol;&#39; attribute of the &bsol;&#39;train&bsol;&#39; step definition in recipe.yaml). The estimator is then joined with the fitted transformer output from the &bsol;&#39;transform&bsol;&#39; step to create a model pipeline. Finally, this model pipeline is evaluated against the transformed training and validation datasets to produce performance metrics; custom metrics are computed according to definitions in `steps/custom_metrics.py` and the &bsol;&#39;function&bsol;&#39; attributes of entries in the &bsol;&#39;custom&bsol;&#39; subsection of the &bsol;&#39;metrics&bsol;&#39; section in recipe.yaml. The model pipeline and its associated parameters, performance metrics, and lineage information are logged to MLflow Tracking, producing an MLflow Run. An example recipe.yaml &bsol;&#39;train&bsol;&#39; step definition is shown below, as well as an example custom metric definition.\\n\\nsteps:\\n  train:\\n    using: custom\\n    estimator_method: estimator_fn\\n\\ncustom_metrics:\\n  - name: weighted_mean_squared_error\\n    function: weighted_mean_squared_error\\n    greater_is_better: False\\n', 'help_string_type': 'text'}\"\n",
       "          click trainUserCode renderMoreInformation \"{'help_string': '&bsol;#quot;&bsol;#quot;&bsol;#quot;\\nsteps/train.py defines customizable logic for specifying your estimator&bsol;&#39;s type and parameters that will be used during training. The estimator type and its parameters are specified via the `estimator_fn` function, an example of which is displayed below (note that a different function name or module can be specified via the &bsol;&#39;estimator_method&bsol;&#39; attribute of the &bsol;&#39;train&bsol;&#39; step definition in recipe.yaml).\\n&bsol;#quot;&bsol;#quot;&bsol;#quot;\\n\\ndef estimator_fn():\\n    &bsol;#quot;&bsol;#quot;&bsol;#quot;\\n    Returns an *unfitted* estimator that defines ``fit()`` and ``predict()`` methods. The estimator&bsol;&#39;s input and output signatures should be compatible with scikit-learn estimators.\\n    &bsol;#quot;&bsol;#quot;&bsol;#quot;\\n', 'help_string_type': 'python'}\"\n",
       "          click evaluateMLPStep renderMoreInformation \"{'help_string': 'The &bsol;&#39;evaluate&bsol;&#39; step evaluates the model pipeline produced by the &bsol;&#39;train&bsol;&#39; step on the test dataset output from the &bsol;&#39;split&bsol;&#39; step, producing performance metrics and model explanations. Performance metrics are compared against configured thresholds to compute a &bsol;&#39;model_validation_status&bsol;&#39;, which indicates whether or not a model is good enough to be registered to the MLflow Model Registry by the subsequent &bsol;&#39;register&bsol;&#39; step. Custom performance metrics are computed according to definitions in `steps/custom_metrics.py` and the &bsol;&#39;function&bsol;&#39; attributes of entries in the &bsol;&#39;custom&bsol;&#39; subsection of the &bsol;&#39;metrics&bsol;&#39; section in recipe.yaml. Model performance thresholds are defined in the &bsol;&#39;validation_criteria&bsol;&#39; section of the &bsol;&#39;evaluate&bsol;&#39; step definition in recipe.yaml. Model performance metrics and explanations are logged to MLflow Tracking using the same MLflow Run produced by the &bsol;&#39;train&bsol;&#39; step. An example recipe.yaml &bsol;&#39;evaluate&bsol;&#39; step definition is shown below, as well as an example custom metric definition.\\n\\nevaluate:\\n  validation_criteria:\\n    - metric: root_mean_squared_error\\n      threshold: 10\\n    - metric: weighted_mean_squared_error\\n      threshold: 20\\n\\ncustom_metrics:\\n  - name: weighted_mean_squared_error\\n    function: weighted_mean_squared_error\\n    greater_is_better: False\\n', 'help_string_type': 'text'}\"\n",
       "          click registerMLPStep renderMoreInformation \"{'help_string': 'The &bsol;&#39;register&bsol;&#39; step checks the &bsol;&#39;model_validation_status&bsol;&#39; output of the preceding &bsol;&#39;evaluate&bsol;&#39; step and, if model validation was successful (as indicated by the &bsol;&#39;VALIDATED&bsol;&#39; status), registers the model pipeline produced by the &bsol;&#39;train&bsol;&#39; step to the MLflow Model Registry. If the &bsol;&#39;model_validation_status&bsol;&#39; does not indicate that the model passed validation checks (i.e. its value is &bsol;&#39;REJECTED&bsol;&#39;), the model pipeline is not registered to the MLflow Model Registry. This validation status check can be disabled by specifying &bsol;&#39;allow_non_validated_model: true&bsol;&#39; in the &bsol;&#39;register&bsol;&#39; step definition of recipe.yaml, in which case the model pipeline is always registered with the MLflow Model Registry when the &bsol;&#39;register&bsol;&#39; step is executed. If the model pipeline is registered to the MLflow Model Registry, a &bsol;&#39;registered_model_version&bsol;&#39; is produced containing the model name (as configured by the &bsol;&#39;model_name&bsol;&#39; attribute of the &bsol;&#39;register&bsol;&#39; step definition in recipe.yaml) and the model version. An example recipe.yaml &bsol;&#39;register&bsol;&#39; step definition is shown below.\\n\\nregister:\\n  allow_non_validated_model: true\\n', 'help_string_type': 'text'}\"\n",
       "          click customMetricsUserCode renderMoreInformation \"{'help_string': '&bsol;#quot;&bsol;#quot;&bsol;#quot;\\nsteps/custom_metrics.py defines customizable logic for specifying custom metrics to compute during model training and evaluation. Custom metric functions defined in `steps/custom_metrics.py` are referenced by the &bsol;&#39;function&bsol;&#39; attributes of entries in the &bsol;&#39;custom&bsol;&#39; subsection of the &bsol;&#39;metrics&bsol;&#39; section in recipe.yaml. For example:\\n\\ncustom_metrics:\\n  - name: weighted_mean_squared_error\\n    function: weighted_mean_squared_error\\n    greater_is_better: False\\n\\nAn example custom_metrics.py file is displayed below.\\n&bsol;#quot;&bsol;#quot;&bsol;#quot;def weighted_mean_squared_error(\\n    eval_df: pandas.DataFrame,\\n    builtin_metrics: Dict[str, int],\\n) -> Dict[str, int]:\\n    &bsol;#quot;&bsol;#quot;&bsol;#quot;\\n    Computes the weighted mean squared error (MSE) metric.\\n\\n    :param eval_df: A Pandas DataFrame containing the following columns:\\n\\n                    - ``&bsol;#quot;prediction&bsol;#quot;``: Predictions produced by submitting input data to the model.\\n                    - ``&bsol;#quot;target&bsol;#quot;``: Ground truth values corresponding to the input data.\\n\\n    :param builtin_metrics: A dictionary containing the built-in metrics that are calculated automatically during model evaluation. The keys are the names of the metrics and the values are the scalar values of the metrics. For more information, see https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.evaluate.\\n    :return: A single-entry dictionary containing the MSE metric. The key is the metric names and the value is the scalar metric value. Note that custom metric functions can return dictionaries with multiple metric entries as well.\\n    &bsol;#quot;&bsol;#quot;&bsol;#quot;\\n', 'help_string_type': 'python'}\"\n",
       "          click splitUserCode renderMoreInformation \"{'help_string': '&bsol;#quot;&bsol;#quot;&bsol;#quot;\\nsteps/split.py defines customizable logic for postprocessing the training, validation, and test datasets prior to model creation via the `create_dataset_filter` function, an example of which is displayed below (note that a different function name or module can be specified via the &bsol;&#39;post_split_filter_method&bsol;&#39; attribute of the &bsol;&#39;split&bsol;&#39; step definition in recipe.yaml).\\n&bsol;#quot;&bsol;#quot;&bsol;#quot;\\n\\nThis module defines the following routines used by the &bsol;&#39;split&bsol;&#39; step of the recipe:\\n- ``create_dataset_filter``: Defines customizable logic for filtering the training, validation,\\n  and test datasets produced by the data splitting procedure. Note that arbitrary transformations\\n  should go into the transform step.\\n\\ndef create_dataset_filter(dataset: DataFrame) -> Series(bool):\\n    Mark rows of the split datasets to be additionally filtered. This function will be called on\\n    the training, validation, and test datasets.\\n    :param dataset: The {train,validation,test} dataset produced by the data splitting procedure.\\n    :return: A Series indicating whether each row should be filtered\\n', 'help_string_type': 'python'}\"\n",
       "          click ingestScoringUserCode renderMoreInformation \"{'help_string': '&bsol;#quot;&bsol;#quot;&bsol;#quot;\\nsteps/ingest.py defines customizable logic for parsing arbitrary dataset formats (i.e. formats that are not natively parsed by MLflow Recipes) via the `load_file_as_dataframe` function. Note that the Parquet, Delta, and Spark SQL dataset formats are natively parsed by MLflow Recipes, and you do not need to define custom logic for parsing them. An example `load_file_as_dataframe` implementation is displayed below (note that a different function name or module can be specified via the &bsol;&#39;loader_method&bsol;&#39; attribute of the &bsol;&#39;data&bsol;&#39; section in recipe.yaml).\\n&bsol;#quot;&bsol;#quot;&bsol;#quot;\\n\\ndef load_file_as_dataframe(\\n    file_path: str,\\n    file_format: str,\\n) -> pandas.DataFrame:\\n    &bsol;#quot;&bsol;#quot;&bsol;#quot;\\n    Load content from the specified dataset file as a Pandas DataFrame.\\n\\n    This method is used to load dataset types that are not natively  managed by MLflow Recipes (datasets that are not in Parquet, Delta Table, or Spark SQL Table format). This method is called once for each file in the dataset, and MLflow Recipes automatically combines the resulting DataFrames together.\\n\\n    :param file_path: The path to the dataset file.\\n    :param file_format: The file format string, such as &bsol;#quot;csv&bsol;#quot;.\\n    :return: A Pandas DataFrame representing the content of the specified file.\\n    &bsol;#quot;&bsol;#quot;&bsol;#quot;\\n', 'help_string_type': 'python'}\"\n",
       "          click ingestScoringMLPStep renderMoreInformation \"{'help_string': 'The &bsol;&#39;ingest_scoring&bsol;&#39; step resolves the dataset specified by the &bsol;&#39;data_scoring&bsol;&#39; section in recipe.yaml and converts it to parquet format, leveraging the custom dataset parsing code defined in `steps/ingest.py` (and referred to by the &bsol;&#39;loader_method&bsol;&#39; attribute of the &bsol;&#39;data_scoring&bsol;&#39; section in recipe.yaml) if necessary. Subsequent steps score this dataset for batch scoring. An example recipe.yaml &bsol;&#39;data_scoring&bsol;&#39; configuration is shown below.\\n\\ndata_scoring:\\n  location: https://nyc-tlc.s3.amazonaws.com/trip+data/yellow_tripdata_2022-01.parquet\\n  using: {{INGEST_DATA_FORMAT|default(&bsol;&#39;parquet&bsol;&#39;)}}\\n  loader_method: load_file_as_dataframe\\n', 'help_string_type': 'text'}\"\n",
       "          click predictMLPStep renderMoreInformation \"{'help_string': 'The &bsol;&#39;predict&bsol;&#39; step uses the model registered by the &bsol;&#39;register&bsol;&#39; step to score the ingested dataset produced by the &bsol;&#39;ingest_scoring&bsol;&#39; step and writes the resulting dataset to the specified output format and location. To get model for scoring, it reads the register step model version artifact. If the register step was cleared, it uses the latest version of the registered model specified by the `model_name` attribute of the recipe.yaml &bsol;&#39;register&bsol;&#39; step definition. To fix a specific model for use in the &bsol;&#39;predict&bsol;&#39; step, provide its model URI as the &bsol;&#39;model_uri&bsol;&#39; attribute of the recipe.yaml &bsol;&#39;predict&bsol;&#39; step definition. An example recipe.yaml &bsol;&#39;predict&bsol;&#39; step definition is shown below.\\nsteps:\\n  predict:\\n    model_uri: &bsol;#quot;models:/taxi_fare_regressor/Production&bsol;#quot; # optional\\n    using: {{OUTPUT_DATA_FORMAT|default(&bsol;&#39;parquet&bsol;&#39;)}}\\n    location: &bsol;#quot;{{OUTPUT_DATA_LOCATION}}&bsol;#quot;\\n', 'help_string_type': 'text'}\"\n",
       "\n",
       "          click recipe renderMoreInformation \"{'help_string_type': 'yaml', 'help_string': '# recipe.yaml is the main configuration file for the recipe. It defines attributes for each step of the recipe, such as the dataset to use (defined in the the &bsol;&#39;ingest&bsol;&#39; step definition) and the metrics to compute during model training & evaluation (defined in the &bsol;&#39;custom_metrics&bsol;&#39; section, which is used by the &bsol;&#39;train&bsol;&#39; and &bsol;&#39;evaluate&bsol;&#39; steps). recipe.yaml files also support value overrides from profiles (located in the &bsol;&#39;profiles&bsol;&#39; subdirectory of the recipe) using Jinja2 templating syntax. An example recipe.yaml file is displayed below.\\n\\nrecipe: &bsol;#quot;regression/v1&bsol;#quot;\\ntarget_col: &bsol;#quot;fare_amount&bsol;#quot;\\nprimary_metric: &bsol;#quot;root_mean_squared_error&bsol;#quot;\\nsteps:\\n  ingest: {{INGEST_CONFIG}}\\n  split:\\n    split_ratios: {{SPLIT_RATIOS|default([0.75, 0.125, 0.125])}}\\n    post_split_filter_method: create_dataset_filter\\n  transform:\\n    using: custom\\n    transformer_method: transformer_fn\\n  train:\\n    using: custom\\n    estimator_method: estimator_fn\\n  evaluate:\\n    validation_criteria:\\n      - metric: root_mean_squared_error\\n        threshold: 10\\n      - metric: mean_absolute_error\\n        threshold: 50\\n      - metric: weighted_mean_squared_error\\n        threshold: 50\\n  register:\\n    allow_non_validated_model: false\\n  ingest_scoring: {{INGEST_SCORING_CONFIG}}\\n  predict:\\n    output: {{PREDICT_OUTPUT_CONFIG}}\\n\\ncustom_metrics:\\n  - name: weighted_mean_squared_error\\n    function: weighted_mean_squared_error\\n    greater_is_better: False\\n'}\"\n",
       "          click dataParquet renderMoreInformation \"{'help_string': 'The ingested parquet representation of the dataset defined in the &bsol;&#39;steps.ingest&bsol;&#39; section of recipe.yaml. Subsequent steps convert this dataset into training, validation, & test sets and use them to develop a model.', 'help_string_type': 'text'}\"\n",
       "          click data renderMoreInformation \"{'help_string': 'The ingested parquet representation of the dataset defined in the &bsol;&#39;steps.ingest&bsol;&#39; section of recipe.yaml. Subsequent steps convert this dataset into training, validation, & test sets and use them to develop a model.', 'help_string_type': 'text'}\"\n",
       "          click splitData0 renderMoreInformation \"{'help_string': 'The training dataset used to train the model. Subsequent steps fit a transformer using this training data, create transformed features, and use the transformed features to fit an estimator, producing a model pipeline consisting of the fitted transformer and the fitted estimator.', 'help_string_type': 'text'}\"\n",
       "          click splitData1 renderMoreInformation \"{'help_string': 'The validation dataset used to evaluate model performance and tune the model pipeline in the train step. It is also used in evaluate step to compute model explanations such as feature importances.', 'help_string_type': 'text'}\"\n",
       "          click splitData2 renderMoreInformation \"{'help_string': 'The test dataset used to evaluate the performance of the model. The &bsol;&#39;evaluate&bsol;&#39; step uses the test dataset to compute a variety of performance metrics.', 'help_string_type': 'text'}\"\n",
       "          click transformedParquet renderMoreInformation \"{'help_string': '1. The transformed training dataset used to fit the estimator component of the model pipeline. Note that training produces a model pipeline consisting of a fitted transformer and a fitted estimator.\\n\\n2. The validation dataset used to evaluate estimator performance and tune the estimator.', 'help_string_type': 'text'}\"\n",
       "          click run renderMoreInformation \"{'help_string': 'The MLflow Tracking Run containing the model pipeline & its parameters, model performance metrics on the training & validation datasets, and lineage information about the current recipe execution. The downstream &bsol;&#39;evaluate&bsol;&#39; step logs performance metrics and model explanations from the test dataset to this MLflow Run.', 'help_string_type': 'text'}\"\n",
       "          click model renderMoreInformation \"{'help_string': 'The model pipeline produced by fitting the estimator defined in `steps/train.py` on the training dataset and preceding it with the fitted transformer output by the &bsol;&#39;transform&bsol;&#39; step.', 'help_string_type': 'text'}\"\n",
       "          click predictedTrainingData renderMoreInformation \"{'help_string': 'The predicted training dataset that is obtained by predicted training data using the fitted model.', 'help_string_type': 'text'}\"\n",
       "          click transformer renderMoreInformation \"{'help_string': 'The fitted transformer produced by fitting the transformer defined in `steps/transform.py` on the training dataset output from the &bsol;&#39;split&bsol;&#39; step. The fitted transformer is the first component of the model pipeline. The subsequent &bsol;&#39;train&bsol;&#39; step fits an estimator and creates a model pipeline consisting of the fitted transformer and the fitted estimator.', 'help_string_type': 'text'}\"\n",
       "          click model_validation_status renderMoreInformation \"{'help_string': 'Boolean status indicating whether or not the model meets the performance criteria for registration to the MLflow Model Registry. Performance criteria are defined in the &bsol;&#39;validation_criteria&bsol;&#39; section of the &bsol;&#39;evaluate&bsol;&#39; step definition in recipe.yaml, as shown in the example below. The subsequent &bsol;&#39;register&bsol;&#39; step checks the model validation status, and, if it is &bsol;&#39;VALIDATED&bsol;&#39;, creates a new model version in the Model Registry corresponding to the trained model pipeline.\\n\\nevaluate:\\n  validation_criteria:\\n    - metric: root_mean_squared_error\\n      threshold: 10\\n    - metric: mean_absolute_error\\n      threshold: 50\\n    - metric: weighted_mean_squared_error\\n      threshold: 20\\n', 'help_string_type': 'text'}\"\n",
       "          click registered_model_version renderMoreInformation \"{'help_string': 'The Model Version in the MLflow Model Registry corresponding to the trained model. A Model Version is produced if the trained model meets the defined performance criteria for model registration or if `allow_non_validated_model: true` is specified in the &bsol;&#39;register&bsol;&#39; step definition of recipe.yaml', 'help_string_type': 'text'}\"\n",
       "          click dataScoringParquet renderMoreInformation \"{'help_string': 'The ingested parquet representation of the dataset defined in the &bsol;&#39;data_scoring&bsol;&#39; section of recipe.yaml. Subsequent steps score this dataset for batch scoring.', 'help_string_type': 'text'}\"\n",
       "          click dataScoring renderMoreInformation \"{'help_string': 'The ingested parquet representation of the dataset defined in the &bsol;&#39;data_scoring&bsol;&#39; section of recipe.yaml. Subsequent steps score this dataset for batch scoring.', 'help_string_type': 'text'}\"\n",
       "          click dataScored renderMoreInformation \"{'help_string': 'The dataset produced by scoring the ingested dataset generated by the &bsol;&#39;ingest_scoring&bsol;&#39; step with the model specified by the the &bsol;&#39;predict&bsol;&#39; step.', 'help_string_type': 'text'}\"\n",
       "\n",
       "      </div>\n",
       "      <div id=\"editor\"></div>\n",
       "    </div>\n",
       "\n",
       "    <script src=\"https://requirejs.org/docs/release/2.1.5/comments/require.js\"></script>\n",
       "    <script type=\"text/javascript\">\n",
       "      require.config({\n",
       "        paths: {\n",
       "            \"mermaid\": \"https://cdn.jsdelivr.net/npm/mermaid@9.3.0/dist/mermaid.min\",\n",
       "            \"ace\": \"https://cdnjs.cloudflare.com/ajax/libs/ace/1.5.1/\",\n",
       "            \"python\": \"https://cdnjs.cloudflare.com/ajax/libs/ace/1.5.1/mode-python.min\",\n",
       "            \"yaml\": \"https://cdnjs.cloudflare.com/ajax/libs/ace/1.5.1/mode-yaml.min\",\n",
       "            \"idle_fingers\": \"https://cdnjs.cloudflare.com/ajax/libs/ace/1.5.1/theme-idle_fingers.min\",\n",
       "        },\n",
       "      });\n",
       "      require([\"mermaid\"],\n",
       "        function (mermaid) {\n",
       "          const config = {\n",
       "            startOnLoad:true,\n",
       "            securityLevel:'loose',\n",
       "            theme: (window.matchMedia && window.matchMedia(\"(prefers-color-scheme: dark)\").matches) ? \"dark\" : \"default\",\n",
       "            themeCSS: \".cluster rect { fill: none; stroke: none; }\",\n",
       "            flowchart:{\n",
       "                useMaxWidth:true,\n",
       "                htmlLabels:true,\n",
       "            }\n",
       "          };\n",
       "          document.querySelector('.mermaid.pane-loading').classList.remove('pane-loading');\n",
       "          mermaid.initialize(config);\n",
       "          mermaid.init();\n",
       "          const nodes = document.querySelectorAll(\".node\");\n",
       "          [...nodes].forEach((node) => {\n",
       "            var nodeInfo = node.getAttribute('title');\n",
       "            // In order to parse the node text as JSON with `help_string` and `help_string_type`\n",
       "            // attributes, single quotes must be replaced with double quotes. However, we also want\n",
       "            // to convert backslashed single quotes to single quotes in the parsed JSON and preserve\n",
       "            // backslashed double quotes in the parsed JSON. Accordingly, we first replace instances\n",
       "            // of the string \\' with \\\\\" . Then, we replace all instances of ' with \" . Finally, we\n",
       "            // replace instances of \\\\\" with '\n",
       "            nodeInfo = nodeInfo && nodeInfo.replace(/\\\\'/g, '\\\\\\\\\"');\n",
       "            nodeInfo = nodeInfo && nodeInfo.replace(/'/g, '\"');\n",
       "            nodeInfo = nodeInfo && nodeInfo.replace(/\\\\\\\\\"/g, \"'\");\n",
       "            if (nodeInfo) {\n",
       "              const nodeLabel = node.querySelector(\".nodeLabel\");\n",
       "              nodeLabel.setAttribute(\"title\", JSON.parse(nodeInfo).help_string)\n",
       "            }\n",
       "          })\n",
       "          resetStyles()\n",
       "          window.editor = null;\n",
       "        }\n",
       "      );\n",
       "\n",
       "      var resetStyles = function() {\n",
       "        const allNodes = document.querySelector('.nodes').querySelectorAll('[id^=\"flowchart-\"]');\n",
       "          [...allNodes].forEach(node => {\n",
       "            const rect = node.firstChild\n",
       "            if (rect) {\n",
       "              rect.style.fill = \"inherit\";\n",
       "              rect.style.stroke = \"inherit\";\n",
       "            }\n",
       "            node.style.fill = \"#F2F5F7\";\n",
       "            node.style.stroke = \"#CDDAE5\";\n",
       "            node.style.color = \"#20272E\";\n",
       "            const span = node.querySelector('span')\n",
       "            const label = node.querySelector('.label')\n",
       "            span.style.color = \"inherit\";\n",
       "            label.style.color = \"inherit\";\n",
       "          });\n",
       "      }\n",
       "      var noOp = function() {}\n",
       "      var renderMoreInformation = function(nodeId) {\n",
       "        resetStyles()\n",
       "        regex = `[id^=\"flowchart-${nodeId}-\"]`\n",
       "        const node = document.querySelector(regex);\n",
       "        var nodeInfo = node.getAttribute('title');\n",
       "        // In order to parse the node text as JSON with `help_string` and `help_string_type`\n",
       "        // attributes, single quotes must be replaced with double quotes. However, we also want\n",
       "        // to convert backslashed single quotes to single quotes in the parsed JSON and preserve\n",
       "        // backslashed double quotes in the parsed JSON. Accordingly, we first replace instances\n",
       "        // of the string \\' with \\\\\" . Then, we replace all instances of ' with \" . Finally, we\n",
       "        // replace instances of \\\\\" with '\n",
       "        nodeInfo = nodeInfo && nodeInfo.replace(/\\\\'/g, '\\\\\\\\\"');\n",
       "        nodeInfo = nodeInfo && nodeInfo.replace(/'/g, '\"');\n",
       "        nodeInfo = nodeInfo && nodeInfo.replace(/\\\\\\\\\"/g, \"'\");\n",
       "        nodeInfo = JSON.parse(nodeInfo)\n",
       "\n",
       "        const rect = node.firstChild;\n",
       "        rect.style.stroke = \"#04355D\";\n",
       "        rect.style.fill = \"#bbdaf4\";\n",
       "        rect.style.color = \"#04355D\";\n",
       "\n",
       "        document.querySelector(\"#editor\").classList.add('pane-loading');\n",
       "        const hideSpinner = () => document.querySelector(\"#editor\").classList.remove('pane-loading');\n",
       "\n",
       "        require([\"ace/ace\"],\n",
       "          function (ace) {\n",
       "            require([\"python\", \"yaml\", \"idle_fingers\"],\n",
       "              function () {\n",
       "                hideSpinner();\n",
       "                if (!window.editor) {\n",
       "                  const editor = ace.edit(\"editor\");\n",
       "                  editor.setTheme(\"ace/theme/idle_fingers\");\n",
       "                  // Wrap text lines for readability\n",
       "                  editor.session.setUseWrapMode(true);\n",
       "                  // Minimize indentation on wrapped lines by setting tab size to 1 character\n",
       "                  // (note that 0 characters does not appear to work. TODO: Find a better approach)\n",
       "                  editor.setOption(\"tabSize\", 1);\n",
       "                  editor.setReadOnly(true);\n",
       "                  // Disable active line highlighting\n",
       "                  editor.setHighlightActiveLine(false);\n",
       "                  // Hide the cursor, the presence of which creates the misconception\n",
       "                  // that the text is editable\n",
       "                  editor.renderer.$cursorLayer.element.style.display = \"none\"\n",
       "                  // Hide the editor gutter, since the window isn't really an editor and instead\n",
       "                  // is intended for displaying text\n",
       "                  editor.renderer.setShowGutter(false);\n",
       "                  // Disable the line length ruler\n",
       "                  editor.setShowPrintMargin(false);\n",
       "                  window.editor = editor;\n",
       "                }\n",
       "                // Set the editor value and the editor session value to the text associated with\n",
       "                // the recipe node; setting the session is important in order to avoid\n",
       "                // obtrusive highlighting\n",
       "                window.editor.setValue(nodeInfo.help_string)\n",
       "                window.editor.session.setValue(nodeInfo.help_string)\n",
       "                window.editor.session.setMode(`ace/mode/${nodeInfo.help_string_type}`);\n",
       "              }, hideSpinner\n",
       "            );\n",
       "          }, hideSpinner\n",
       "        );\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "  </body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r.inspect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcbef991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/04/03 11:52:37 INFO mlflow.recipes.step: Running step ingest...\n",
      "****************************************************************************************************\n",
      "csv\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "    <head>\n",
       "        <meta charset=\"UTF-8\">\n",
       "        <title>Ingest@my_project</title>\n",
       "        <style>\n",
       "            h1.title {\n",
       "            color: #4287f5;\n",
       "            }\n",
       "            h2.step-title {\n",
       "                color : #4287f5;\n",
       "            }\n",
       "            .tab {\n",
       "                overflow: hidden;\n",
       "                border: 1px solid #ccc;\n",
       "                background-color: #f1f1f1;\n",
       "            }\n",
       "\n",
       "            .tab button {\n",
       "                background-color: inherit;\n",
       "                float: left;\n",
       "                border: none;\n",
       "                outline: none;\n",
       "                cursor: pointer;\n",
       "                padding: 14px 16px;\n",
       "                transition: 0.3s;\n",
       "            }\n",
       "\n",
       "            .tab button:hover {\n",
       "                background-color: #ddd;\n",
       "            }\n",
       "\n",
       "            .tab button.active {\n",
       "                background-color: #ccc;\n",
       "            }\n",
       "\n",
       "            .tabcontent {\n",
       "                display: block;\n",
       "                padding: 6px 12px;\n",
       "                border: 1px solid #ccc;\n",
       "                border-top: none;\n",
       "            }\n",
       "\n",
       "            .content-hide {\n",
       "                display: none;\n",
       "            }\n",
       "\n",
       "            .content-active {\n",
       "                display: block;\n",
       "            }\n",
       "            h3.section-title {\n",
       "                color: #57a8de;\n",
       "            }\n",
       "            .dataset-container {\n",
       "                width: max;\n",
       "                overflow-x: auto;\n",
       "                white-space: nowrap;\n",
       "            }\n",
       "            .stacktrace-container {\n",
       "                max-height: 300px;\n",
       "                overflow: auto;\n",
       "                display: flex;\n",
       "                flex-direction: column-reverse;\n",
       "                white-space: pre-wrap;\n",
       "            }\n",
       "        </style>\n",
       "    </head>\n",
       "   <body>\n",
       "        <div class=\"tab\">\n",
       "            <div class=\"button-container-j3k7t7\">\n",
       "                \n",
       "                    <button id=0 class=\"tablink-j3k7t7\">\n",
       "                        Data Profile\n",
       "                    </button>\n",
       "                \n",
       "                    <button id=1 class=\"tablink-j3k7t7\">\n",
       "                        Data Schema\n",
       "                    </button>\n",
       "                \n",
       "                    <button id=2 class=\"tablink-j3k7t7\">\n",
       "                        Data Preview\n",
       "                    </button>\n",
       "                \n",
       "                    <button id=3 class=\"tablink-j3k7t7\">\n",
       "                        Run Summary\n",
       "                    </button>\n",
       "                \n",
       "            </div>\n",
       "        </div>\n",
       "        <div class=\"tabcontent\">\n",
       "            \n",
       "                <div class=\"content-j3k7t7 content-hide\"><iframe srcdoc='\n",
       "        &lt;div style=&quot;background-color: white&quot;&gt;\n",
       "        &lt;script&gt;!function(){let t=window.URL;window.URL=function(n,e){return&quot;string&quot;==typeof e&amp;&amp;e.startsWith(&quot;blob:&quot;)?new URL(e):new t(n,e)}}();&lt;/script&gt;\n",
       "        &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js&quot;&gt;&lt;/script&gt;\n",
       "        &lt;link rel=&quot;import&quot; href=&quot;https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html&quot; &gt;\n",
       "        &lt;facets-overview id=&quot;facets&quot; proto-input=&quot;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&quot; compare-mode=&quot;True&quot;&gt;&lt;/facets-overview&gt;\n",
       "        &lt;/div&gt;\n",
       "    ' width='100%' height='500' frameborder='0'></iframe></div>\n",
       "            \n",
       "                <div class=\"content-j3k7t7 content-hide\"><div style=\"max-height: 500px; overflow: scroll;\"><style type=\"text/css\">\n",
       "#T_26a35 table {\n",
       "  border: 1px solid grey;\n",
       "  text-align: left;\n",
       "  padding: 5px;\n",
       "}\n",
       "#T_26a35  th {\n",
       "  border: 1px solid grey;\n",
       "  text-align: left;\n",
       "  padding: 5px;\n",
       "}\n",
       "#T_26a35  td {\n",
       "  border: 1px solid grey;\n",
       "  text-align: left;\n",
       "  padding: 5px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_26a35\" style=\"border-collapse:collapse\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_26a35_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
       "      <th id=\"T_26a35_level0_col1\" class=\"col_heading level0 col1\" >type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_26a35_row0_col0\" class=\"data row0 col0\" >Unnamed: 0</td>\n",
       "      <td id=\"T_26a35_row0_col1\" class=\"data row0 col1\" >integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_26a35_row1_col0\" class=\"data row1 col0\" >col1</td>\n",
       "      <td id=\"T_26a35_row1_col1\" class=\"data row1 col1\" >integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_26a35_row2_col0\" class=\"data row2 col0\" >col2</td>\n",
       "      <td id=\"T_26a35_row2_col1\" class=\"data row2 col1\" >integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_26a35_row3_col0\" class=\"data row3 col0\" >target</td>\n",
       "      <td id=\"T_26a35_row3_col1\" class=\"data row3 col1\" >string</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "            \n",
       "                <div class=\"content-j3k7t7 content-hide\"><div style=\"max-height: 500px; overflow: scroll;\"><style type=\"text/css\">\n",
       "#T_69fad table {\n",
       "  border: 1px solid grey;\n",
       "  text-align: left;\n",
       "  padding: 5px;\n",
       "}\n",
       "#T_69fad  th {\n",
       "  border: 1px solid grey;\n",
       "  text-align: left;\n",
       "  padding: 5px;\n",
       "}\n",
       "#T_69fad  td {\n",
       "  border: 1px solid grey;\n",
       "  text-align: left;\n",
       "  padding: 5px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_69fad\" style=\"border-collapse:collapse\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_69fad_level0_col0\" class=\"col_heading level0 col0\" >Unnamed: 0</th>\n",
       "      <th id=\"T_69fad_level0_col1\" class=\"col_heading level0 col1\" >col1</th>\n",
       "      <th id=\"T_69fad_level0_col2\" class=\"col_heading level0 col2\" >col2</th>\n",
       "      <th id=\"T_69fad_level0_col3\" class=\"col_heading level0 col3\" >target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_69fad_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_69fad_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_69fad_row0_col2\" class=\"data row0 col2\" >4</td>\n",
       "      <td id=\"T_69fad_row0_col3\" class=\"data row0 col3\" >a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_69fad_row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "      <td id=\"T_69fad_row1_col1\" class=\"data row1 col1\" >2</td>\n",
       "      <td id=\"T_69fad_row1_col2\" class=\"data row1 col2\" >5</td>\n",
       "      <td id=\"T_69fad_row1_col3\" class=\"data row1 col3\" >b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_69fad_row2_col0\" class=\"data row2 col0\" >2</td>\n",
       "      <td id=\"T_69fad_row2_col1\" class=\"data row2 col1\" >3</td>\n",
       "      <td id=\"T_69fad_row2_col2\" class=\"data row2 col2\" >6</td>\n",
       "      <td id=\"T_69fad_row2_col3\" class=\"data row2 col3\" >c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "            \n",
       "                <div class=\"content-j3k7t7 content-hide\"><p><strong>Number of rows ingested:</strong> <code>3</code></p><p><strong>Dataset source location:</strong> <code>['C:\\\\Users\\\\honek\\\\Desktop\\\\ML_project_from_scratch\\\\my_project\\\\data\\\\df.csv']</code></p><p><strong>Run duration (s)</strong>: 0.368</p><p><strong>Last updated:</strong> 2024-04-03 11:52:38</p></div>\n",
       "            \n",
       "        </div>\n",
       "        <script>\n",
       "            function onclickTab(event) {\n",
       "                 const tablinks = document.getElementsByClassName(\"tablink-j3k7t7\");\n",
       "                for (i = 0; i < tablinks.length; i++) {\n",
       "                    tablinks[i].className = tablinks[i].className.replace(\"active\", \"\");\n",
       "                }\n",
       "                event.target.classList.add(\"active\");\n",
       "\n",
       "                const tabId = event.target.id;\n",
       "                const tabContents = document.getElementsByClassName(\"content-j3k7t7\");\n",
       "                for (i = 0; i < tabContents.length; i++) {\n",
       "                    tabContents[i].className = tabContents[i].className.replace(\"content-active\", \"content-hide\");\n",
       "                }\n",
       "                tabContents[tabId].classList.add(\"content-active\");\n",
       "            }\n",
       "            (function() {\n",
       "                const buttonsContainer = document.getElementsByClassName(\"button-container-j3k7t7\")[0]\n",
       "                buttonsContainer.addEventListener(\"click\", onclickTab);\n",
       "\n",
       "                const tablinks = document.getElementsByClassName(\"tablink-j3k7t7\");\n",
       "                tablinks[0].classList.add(\"active\");\n",
       "                const tabContents = document.getElementsByClassName(\"content-j3k7t7\");\n",
       "                tabContents[0].classList.add(\"content-active\");\n",
       "            })()\n",
       "        </script>\n",
       "   </body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r.run(\"ingest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52534f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['make', '--help'], returncode=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run([\"make\", \"--help\"], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec51da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32e56e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingested_data_path = 'C:/Users/honek/.mlflow/recipes/1991bd051264205cf200c35d8ec0ad004b0d606a1a493437e999d7871c3781fe/steps/ingest/outputs/dataset.parquet'\n",
    "df_from_parquet = pd.read_parquet(ingested_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c6822c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  col1  col2 target\n",
       "0           0     1     4      a\n",
       "1           1     2     5      b\n",
       "2           2     3     6      c"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ed4a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20262063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22f0ef09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8032bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 3D array:\n",
      "[[[0.69383022 0.07017858 0.85192124 0.06816079]\n",
      "  [0.77628281 0.83764855 0.8056396  0.05533373]\n",
      "  [0.95258032 0.97714278 0.57644598 0.96235275]]\n",
      "\n",
      " [[0.247656   0.42381255 0.55650927 0.00706274]\n",
      "  [0.29362226 0.989516   0.66527283 0.66343495]\n",
      "  [0.25978969 0.4705281  0.95732501 0.19071816]]]\n",
      "Flattened 2D array:\n",
      "[[0.69383022 0.07017858 0.85192124 0.06816079 0.77628281 0.83764855\n",
      "  0.8056396  0.05533373 0.95258032 0.97714278 0.57644598 0.96235275]\n",
      " [0.247656   0.42381255 0.55650927 0.00706274 0.29362226 0.989516\n",
      "  0.66527283 0.66343495 0.25978969 0.4705281  0.95732501 0.19071816]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example 3D array\n",
    "array_3d = np.random.rand(2, 3, 4)  # Example 3D array of shape (2, 3, 4)\n",
    "\n",
    "# Reshape the array to flatten the last two dimensions\n",
    "array_2d = array_3d.reshape(-1, array_3d.shape[1] * array_3d.shape[2])\n",
    "\n",
    "# Output the original and flattened arrays\n",
    "print(\"Original 3D array:\")\n",
    "print(array_3d)\n",
    "print(\"Flattened 2D array:\")\n",
    "print(array_2d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_project",
   "language": "python",
   "name": "my_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
